{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNNs working on a different cohort \n",
    "\n",
    "In this notebook, we obtain the results for GNNs, baseline, and non-GNN models using a completely different cohort of Late Onset Alzheimer's Disease subjects and healthy controls.\n",
    "\n",
    "The graph datasets were built using the network that obtained best performance in ADNI dataset (both with PET and PET&DX labellings), which is AD PPT-Ohmnet. \n",
    "\n",
    "*Disclaimer*: please note that many parts of this code require the preprocessed data from LOAD (both genetic and diagnostic related) as input. This data has not been uploaded to the repository for privacy reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime, pickle\n",
    "from create_datasets import create_nx_datasets, create_splits\n",
    "from ml_models.machine_learning_models import create_class_LOAD, baseline_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Obtain genes of interest**\n",
    "\n",
    "Using DisGeNET to get Gene-Disease-Associations (GDAs) to Alzheimer's Disease (AD gene set) and other neurodegenerative diseases (ND). This is already obtained from [first part of the results](1_main_methodology.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Obtain biological networks**\n",
    "\n",
    "Using genes of interst obtained from DisGeNET, obtain PPI between them from STRING. This is already obtained from [first part of the results](1_main_methodology.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Data preprocessing**\n",
    "\n",
    "Please refer to `data_preprocessing` subdirectory for this part.\n",
    "1. [make_BED_files.R](data_preprocessing/make_BED_files.R) creates BED files with the genomic coordinates of the genes of interest. This is already obtained from [first part of the results](1_main_methodology.ipynb).\n",
    "2. [extract_and_annotate_missense_LOAD.sh](data_preprocessing/extract_and_annotate_missense_LOAD.sh) is the script for obtaining missense variants from the VCF files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Create graph datasets**\n",
    "\n",
    "Create graph datasets (one graph representing each patient) for different targets with LOAD dataset. As previously stated, we only obtain graph datasets using AD PPT-Ohmnet network (named as `snap_brain` in the following code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Network used: AD snap_brain\n",
      "# nodes = 29\n",
      "# edges = 52\n",
      "\n",
      "Dataset used: LOAD\n",
      "(11, 1678)\n",
      "(11, 1608)\n",
      "missense\n",
      "(29, 1599)\n",
      "Creating samples graphs...\n",
      "Class: LOAD. Found 1014 positive subjects out of 1599\n",
      "Sample graph used: # nodes = 29 # edges = 52\n",
      "Density = 0.12807881773399016 Diameter = 6\n",
      "Coding: number of missense variants per node\n",
      "Resulting dataset saved at: data/graph_datasets/LOAD/AD_PPI_snap_brain_missense.pkl\n",
      "\n",
      "Processing time: 0:00:55.406044\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "networks = ['snap_brain']\n",
    "\n",
    "for network in networks:\n",
    "\n",
    "    outdir = f'data/graph_datasets/LOAD'\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "    print()\n",
    "\n",
    "    result_nodes = create_nx_datasets.main('data', 'LOAD', 'LOAD', 'AD', network, 'missense', None)\n",
    "    print('Coding: number of missense variants per node')\n",
    "\n",
    "    outfile = f'{outdir}/AD_PPI_{network}_missense.pkl'\n",
    "    print('Resulting dataset saved at:', outfile)\n",
    "    print()\n",
    "\n",
    "    with open(outfile, 'wb') as f:\n",
    "        pickle.dump(result_nodes, f)\n",
    "\n",
    "    result_nodes_time = datetime.datetime.now()\n",
    "    print('Processing time:', result_nodes_time - start_time)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Graph classification with GNNs**\n",
    "\n",
    "We then evaluated and tested different GNN configurations in the framework called [GraphGym](https://github.com/snap-stanford/GraphGym) (You *et al.*, 2020).\n",
    "\n",
    "Configuration and grid files employed are in the subdirectory [graphgym_files](graphgym_files).\n",
    "\n",
    "Summarized results obtained by GraphGym in LOAD dataset are in **COMPLETE**\n",
    "\n",
    "We run GraphGym 10 times, with the 10 different splits generated by 10-Fold Stratified Cross-Validation (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD\n",
      "Fold -  1   |   train -  [526 913]   |   test -  [ 59 101]\n",
      "Fold -  2   |   train -  [526 913]   |   test -  [ 59 101]\n",
      "Fold -  3   |   train -  [526 913]   |   test -  [ 59 101]\n",
      "Fold -  4   |   train -  [526 913]   |   test -  [ 59 101]\n",
      "Fold -  5   |   train -  [526 913]   |   test -  [ 59 101]\n",
      "Fold -  6   |   train -  [527 912]   |   test -  [ 58 102]\n",
      "Fold -  7   |   train -  [527 912]   |   test -  [ 58 102]\n",
      "Fold -  8   |   train -  [527 912]   |   test -  [ 58 102]\n",
      "Fold -  9   |   train -  [527 912]   |   test -  [ 58 102]\n",
      "Fold -  10   |   train -  [527 913]   |   test -  [ 58 101]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create split for using it in GraphGym and non-GNN models\n",
    "# Splits are obtained through 10-Fold Stratied Cross Validation\n",
    "\n",
    "create_splits.create_folds_stratified_cv('LOAD', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Analyze results**\n",
    "\n",
    "We obtained best GNN configurations in each split. Next, we selected the common configuration in all splits and obtained average and standard deviation over the 10 splits of several performance metrics (Accuracy, Precision, Recall, F1, AUC).\n",
    "\n",
    "Please refer to the following notebook **COMPLETE!** to see how we compared GNNs performance against other non-GNN models and the corresponding baseline model."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e0466fb38f8b8207bee76f1d5f01e5f82e3be8917a80d900a987709dfd81e7a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
